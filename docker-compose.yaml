version: '2'
services:
  namenode:
    image: hadoop-3:latest
    container_name: namenode
    networks:
      - hadoop
    ports:
      - 9870:9870  # hdfs namenode ui
    command: namenode
    restart: always

  datanode:
    image: hadoop-3:latest
    container_name: datanode
    depends_on: 
      - namenode
    networks:
      - hadoop
    ports:
      - 9864:9864  # hdfs datanode ui
    command: datanode
    restart: always

  resourcemanager:
    image: hadoop-3:latest
    container_name: resourcemanager
    depends_on: 
      - datanode
      - namenode
    ports:
      - 8088:8088 # yarn resourcemanager ui
    networks:
      - hadoop
    command: resourcemanager
    restart: always

  nodemanager:
    image: hadoop-3:latest
    container_name: nodemanager
    depends_on: 
      - resourcemanager
    networks:
      - hadoop
    ports:
      - 8042:8042 # yarn nodemanager ui
    command: nodemanager
    restart: always

  spark:
    image: hadoop-3:latest
    container_name: spark
    depends_on: 
      - resourcemanager
      - namenode
      - datanode
    ports: # only if use SPARK own resource manager
      - 8081:8081 # spark worker ui
      - 8080:8080 # spark master ui
      - 8998:8998 # livy localhost:8998/ui
    networks:
      - hadoop
    command: spark rdd/count_lines.py
    restart: always

  hive:
    image: hadoop-3:latest
    container_name: hive
    depends_on: 
      - resourcemanager
      - namenode
      - datanode
    ports:
      - 10002:10002
    networks:
      - hadoop
    command: hive

  hue:
    image: hue:latest
    container_name: hue
    depends_on:
      - hive
    ports:
      - 8888:8888
    networks:
      - hadoop
    command: ./build/env/bin/hue runserver_plus 0.0.0.0:8888
    restart: always

networks:
  hadoop:

volumes:
  node_manager_tmp:
